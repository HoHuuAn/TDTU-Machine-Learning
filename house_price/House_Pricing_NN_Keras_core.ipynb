{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "0e33dd07",
      "metadata": {
        "id": "0e33dd07"
      },
      "outputs": [],
      "source": [
        "#import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "3427d55c",
      "metadata": {
        "id": "3427d55c",
        "outputId": "5863f747-9d64-47d5-b24c-0b8912e37c06"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <td>7129300520</td>\n",
              "      <td>6414100192</td>\n",
              "      <td>5631500400</td>\n",
              "      <td>2487200875</td>\n",
              "      <td>1954400510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>date</th>\n",
              "      <td>20141013T000000</td>\n",
              "      <td>20141209T000000</td>\n",
              "      <td>20150225T000000</td>\n",
              "      <td>20141209T000000</td>\n",
              "      <td>20150218T000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>price</th>\n",
              "      <td>221900.0</td>\n",
              "      <td>538000.0</td>\n",
              "      <td>180000.0</td>\n",
              "      <td>604000.0</td>\n",
              "      <td>510000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bedrooms</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bathrooms</th>\n",
              "      <td>1.0</td>\n",
              "      <td>2.25</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sqft_living</th>\n",
              "      <td>1180</td>\n",
              "      <td>2570</td>\n",
              "      <td>770</td>\n",
              "      <td>1960</td>\n",
              "      <td>1680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sqft_lot</th>\n",
              "      <td>5650</td>\n",
              "      <td>7242</td>\n",
              "      <td>10000</td>\n",
              "      <td>5000</td>\n",
              "      <td>8080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>floors</th>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>waterfront</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>view</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>condition</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>grade</th>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sqft_above</th>\n",
              "      <td>1180</td>\n",
              "      <td>2170</td>\n",
              "      <td>770</td>\n",
              "      <td>1050</td>\n",
              "      <td>1680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sqft_basement</th>\n",
              "      <td>0</td>\n",
              "      <td>400</td>\n",
              "      <td>0</td>\n",
              "      <td>910</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>yr_built</th>\n",
              "      <td>1955</td>\n",
              "      <td>1951</td>\n",
              "      <td>1933</td>\n",
              "      <td>1965</td>\n",
              "      <td>1987</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>yr_renovated</th>\n",
              "      <td>0</td>\n",
              "      <td>1991</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zipcode</th>\n",
              "      <td>98178</td>\n",
              "      <td>98125</td>\n",
              "      <td>98028</td>\n",
              "      <td>98136</td>\n",
              "      <td>98074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lat</th>\n",
              "      <td>47.5112</td>\n",
              "      <td>47.721</td>\n",
              "      <td>47.7379</td>\n",
              "      <td>47.5208</td>\n",
              "      <td>47.6168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>long</th>\n",
              "      <td>-122.257</td>\n",
              "      <td>-122.319</td>\n",
              "      <td>-122.233</td>\n",
              "      <td>-122.393</td>\n",
              "      <td>-122.045</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sqft_living15</th>\n",
              "      <td>1340</td>\n",
              "      <td>1690</td>\n",
              "      <td>2720</td>\n",
              "      <td>1360</td>\n",
              "      <td>1800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sqft_lot15</th>\n",
              "      <td>5650</td>\n",
              "      <td>7639</td>\n",
              "      <td>8062</td>\n",
              "      <td>5000</td>\n",
              "      <td>7503</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                             0                1                2  \\\n",
              "id                  7129300520       6414100192       5631500400   \n",
              "date           20141013T000000  20141209T000000  20150225T000000   \n",
              "price                 221900.0         538000.0         180000.0   \n",
              "bedrooms                     3                3                2   \n",
              "bathrooms                  1.0             2.25              1.0   \n",
              "sqft_living               1180             2570              770   \n",
              "sqft_lot                  5650             7242            10000   \n",
              "floors                     1.0              2.0              1.0   \n",
              "waterfront                   0                0                0   \n",
              "view                         0                0                0   \n",
              "condition                    3                3                3   \n",
              "grade                        7                7                6   \n",
              "sqft_above                1180             2170              770   \n",
              "sqft_basement                0              400                0   \n",
              "yr_built                  1955             1951             1933   \n",
              "yr_renovated                 0             1991                0   \n",
              "zipcode                  98178            98125            98028   \n",
              "lat                    47.5112           47.721          47.7379   \n",
              "long                  -122.257         -122.319         -122.233   \n",
              "sqft_living15             1340             1690             2720   \n",
              "sqft_lot15                5650             7639             8062   \n",
              "\n",
              "                             3                4  \n",
              "id                  2487200875       1954400510  \n",
              "date           20141209T000000  20150218T000000  \n",
              "price                 604000.0         510000.0  \n",
              "bedrooms                     4                3  \n",
              "bathrooms                  3.0              2.0  \n",
              "sqft_living               1960             1680  \n",
              "sqft_lot                  5000             8080  \n",
              "floors                     1.0              1.0  \n",
              "waterfront                   0                0  \n",
              "view                         0                0  \n",
              "condition                    5                3  \n",
              "grade                        7                8  \n",
              "sqft_above                1050             1680  \n",
              "sqft_basement              910                0  \n",
              "yr_built                  1965             1987  \n",
              "yr_renovated                 0                0  \n",
              "zipcode                  98136            98074  \n",
              "lat                    47.5208          47.6168  \n",
              "long                  -122.393         -122.045  \n",
              "sqft_living15             1360             1800  \n",
              "sqft_lot15                5000             7503  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#import Data\n",
        "df = pd.read_csv('kc_house_data.csv')\n",
        "df.head(5).T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "b553796f",
      "metadata": {
        "id": "b553796f",
        "outputId": "05fa9a2b-8d7a-40f1-9233-00a7dce24b6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 21613 entries, 0 to 21612\n",
            "Data columns (total 21 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   id             21613 non-null  int64  \n",
            " 1   date           21613 non-null  object \n",
            " 2   price          21613 non-null  float64\n",
            " 3   bedrooms       21613 non-null  int64  \n",
            " 4   bathrooms      21613 non-null  float64\n",
            " 5   sqft_living    21613 non-null  int64  \n",
            " 6   sqft_lot       21613 non-null  int64  \n",
            " 7   floors         21613 non-null  float64\n",
            " 8   waterfront     21613 non-null  int64  \n",
            " 9   view           21613 non-null  int64  \n",
            " 10  condition      21613 non-null  int64  \n",
            " 11  grade          21613 non-null  int64  \n",
            " 12  sqft_above     21613 non-null  int64  \n",
            " 13  sqft_basement  21613 non-null  int64  \n",
            " 14  yr_built       21613 non-null  int64  \n",
            " 15  yr_renovated   21613 non-null  int64  \n",
            " 16  zipcode        21613 non-null  int64  \n",
            " 17  lat            21613 non-null  float64\n",
            " 18  long           21613 non-null  float64\n",
            " 19  sqft_living15  21613 non-null  int64  \n",
            " 20  sqft_lot15     21613 non-null  int64  \n",
            "dtypes: float64(5), int64(15), object(1)\n",
            "memory usage: 3.5+ MB\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <td>21613.0</td>\n",
              "      <td>4.580302e+09</td>\n",
              "      <td>2.876566e+09</td>\n",
              "      <td>1.000102e+06</td>\n",
              "      <td>2.123049e+09</td>\n",
              "      <td>3.904930e+09</td>\n",
              "      <td>7.308900e+09</td>\n",
              "      <td>9.900000e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>price</th>\n",
              "      <td>21613.0</td>\n",
              "      <td>5.400881e+05</td>\n",
              "      <td>3.671272e+05</td>\n",
              "      <td>7.500000e+04</td>\n",
              "      <td>3.219500e+05</td>\n",
              "      <td>4.500000e+05</td>\n",
              "      <td>6.450000e+05</td>\n",
              "      <td>7.700000e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bedrooms</th>\n",
              "      <td>21613.0</td>\n",
              "      <td>3.370842e+00</td>\n",
              "      <td>9.300618e-01</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>3.000000e+00</td>\n",
              "      <td>3.000000e+00</td>\n",
              "      <td>4.000000e+00</td>\n",
              "      <td>3.300000e+01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bathrooms</th>\n",
              "      <td>21613.0</td>\n",
              "      <td>2.114757e+00</td>\n",
              "      <td>7.701632e-01</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.750000e+00</td>\n",
              "      <td>2.250000e+00</td>\n",
              "      <td>2.500000e+00</td>\n",
              "      <td>8.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sqft_living</th>\n",
              "      <td>21613.0</td>\n",
              "      <td>2.079900e+03</td>\n",
              "      <td>9.184409e+02</td>\n",
              "      <td>2.900000e+02</td>\n",
              "      <td>1.427000e+03</td>\n",
              "      <td>1.910000e+03</td>\n",
              "      <td>2.550000e+03</td>\n",
              "      <td>1.354000e+04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sqft_lot</th>\n",
              "      <td>21613.0</td>\n",
              "      <td>1.510697e+04</td>\n",
              "      <td>4.142051e+04</td>\n",
              "      <td>5.200000e+02</td>\n",
              "      <td>5.040000e+03</td>\n",
              "      <td>7.618000e+03</td>\n",
              "      <td>1.068800e+04</td>\n",
              "      <td>1.651359e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>floors</th>\n",
              "      <td>21613.0</td>\n",
              "      <td>1.494309e+00</td>\n",
              "      <td>5.399889e-01</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.500000e+00</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>3.500000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>waterfront</th>\n",
              "      <td>21613.0</td>\n",
              "      <td>7.541757e-03</td>\n",
              "      <td>8.651720e-02</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>view</th>\n",
              "      <td>21613.0</td>\n",
              "      <td>2.343034e-01</td>\n",
              "      <td>7.663176e-01</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>4.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>condition</th>\n",
              "      <td>21613.0</td>\n",
              "      <td>3.409430e+00</td>\n",
              "      <td>6.507430e-01</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>3.000000e+00</td>\n",
              "      <td>3.000000e+00</td>\n",
              "      <td>4.000000e+00</td>\n",
              "      <td>5.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>grade</th>\n",
              "      <td>21613.0</td>\n",
              "      <td>7.656873e+00</td>\n",
              "      <td>1.175459e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>7.000000e+00</td>\n",
              "      <td>7.000000e+00</td>\n",
              "      <td>8.000000e+00</td>\n",
              "      <td>1.300000e+01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sqft_above</th>\n",
              "      <td>21613.0</td>\n",
              "      <td>1.788391e+03</td>\n",
              "      <td>8.280910e+02</td>\n",
              "      <td>2.900000e+02</td>\n",
              "      <td>1.190000e+03</td>\n",
              "      <td>1.560000e+03</td>\n",
              "      <td>2.210000e+03</td>\n",
              "      <td>9.410000e+03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sqft_basement</th>\n",
              "      <td>21613.0</td>\n",
              "      <td>2.915090e+02</td>\n",
              "      <td>4.425750e+02</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>5.600000e+02</td>\n",
              "      <td>4.820000e+03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>yr_built</th>\n",
              "      <td>21613.0</td>\n",
              "      <td>1.971005e+03</td>\n",
              "      <td>2.937341e+01</td>\n",
              "      <td>1.900000e+03</td>\n",
              "      <td>1.951000e+03</td>\n",
              "      <td>1.975000e+03</td>\n",
              "      <td>1.997000e+03</td>\n",
              "      <td>2.015000e+03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>yr_renovated</th>\n",
              "      <td>21613.0</td>\n",
              "      <td>8.440226e+01</td>\n",
              "      <td>4.016792e+02</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>2.015000e+03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zipcode</th>\n",
              "      <td>21613.0</td>\n",
              "      <td>9.807794e+04</td>\n",
              "      <td>5.350503e+01</td>\n",
              "      <td>9.800100e+04</td>\n",
              "      <td>9.803300e+04</td>\n",
              "      <td>9.806500e+04</td>\n",
              "      <td>9.811800e+04</td>\n",
              "      <td>9.819900e+04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lat</th>\n",
              "      <td>21613.0</td>\n",
              "      <td>4.756005e+01</td>\n",
              "      <td>1.385637e-01</td>\n",
              "      <td>4.715590e+01</td>\n",
              "      <td>4.747100e+01</td>\n",
              "      <td>4.757180e+01</td>\n",
              "      <td>4.767800e+01</td>\n",
              "      <td>4.777760e+01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>long</th>\n",
              "      <td>21613.0</td>\n",
              "      <td>-1.222139e+02</td>\n",
              "      <td>1.408283e-01</td>\n",
              "      <td>-1.225190e+02</td>\n",
              "      <td>-1.223280e+02</td>\n",
              "      <td>-1.222300e+02</td>\n",
              "      <td>-1.221250e+02</td>\n",
              "      <td>-1.213150e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sqft_living15</th>\n",
              "      <td>21613.0</td>\n",
              "      <td>1.986552e+03</td>\n",
              "      <td>6.853913e+02</td>\n",
              "      <td>3.990000e+02</td>\n",
              "      <td>1.490000e+03</td>\n",
              "      <td>1.840000e+03</td>\n",
              "      <td>2.360000e+03</td>\n",
              "      <td>6.210000e+03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sqft_lot15</th>\n",
              "      <td>21613.0</td>\n",
              "      <td>1.276846e+04</td>\n",
              "      <td>2.730418e+04</td>\n",
              "      <td>6.510000e+02</td>\n",
              "      <td>5.100000e+03</td>\n",
              "      <td>7.620000e+03</td>\n",
              "      <td>1.008300e+04</td>\n",
              "      <td>8.712000e+05</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 count          mean           std           min  \\\n",
              "id             21613.0  4.580302e+09  2.876566e+09  1.000102e+06   \n",
              "price          21613.0  5.400881e+05  3.671272e+05  7.500000e+04   \n",
              "bedrooms       21613.0  3.370842e+00  9.300618e-01  0.000000e+00   \n",
              "bathrooms      21613.0  2.114757e+00  7.701632e-01  0.000000e+00   \n",
              "sqft_living    21613.0  2.079900e+03  9.184409e+02  2.900000e+02   \n",
              "sqft_lot       21613.0  1.510697e+04  4.142051e+04  5.200000e+02   \n",
              "floors         21613.0  1.494309e+00  5.399889e-01  1.000000e+00   \n",
              "waterfront     21613.0  7.541757e-03  8.651720e-02  0.000000e+00   \n",
              "view           21613.0  2.343034e-01  7.663176e-01  0.000000e+00   \n",
              "condition      21613.0  3.409430e+00  6.507430e-01  1.000000e+00   \n",
              "grade          21613.0  7.656873e+00  1.175459e+00  1.000000e+00   \n",
              "sqft_above     21613.0  1.788391e+03  8.280910e+02  2.900000e+02   \n",
              "sqft_basement  21613.0  2.915090e+02  4.425750e+02  0.000000e+00   \n",
              "yr_built       21613.0  1.971005e+03  2.937341e+01  1.900000e+03   \n",
              "yr_renovated   21613.0  8.440226e+01  4.016792e+02  0.000000e+00   \n",
              "zipcode        21613.0  9.807794e+04  5.350503e+01  9.800100e+04   \n",
              "lat            21613.0  4.756005e+01  1.385637e-01  4.715590e+01   \n",
              "long           21613.0 -1.222139e+02  1.408283e-01 -1.225190e+02   \n",
              "sqft_living15  21613.0  1.986552e+03  6.853913e+02  3.990000e+02   \n",
              "sqft_lot15     21613.0  1.276846e+04  2.730418e+04  6.510000e+02   \n",
              "\n",
              "                        25%           50%           75%           max  \n",
              "id             2.123049e+09  3.904930e+09  7.308900e+09  9.900000e+09  \n",
              "price          3.219500e+05  4.500000e+05  6.450000e+05  7.700000e+06  \n",
              "bedrooms       3.000000e+00  3.000000e+00  4.000000e+00  3.300000e+01  \n",
              "bathrooms      1.750000e+00  2.250000e+00  2.500000e+00  8.000000e+00  \n",
              "sqft_living    1.427000e+03  1.910000e+03  2.550000e+03  1.354000e+04  \n",
              "sqft_lot       5.040000e+03  7.618000e+03  1.068800e+04  1.651359e+06  \n",
              "floors         1.000000e+00  1.500000e+00  2.000000e+00  3.500000e+00  \n",
              "waterfront     0.000000e+00  0.000000e+00  0.000000e+00  1.000000e+00  \n",
              "view           0.000000e+00  0.000000e+00  0.000000e+00  4.000000e+00  \n",
              "condition      3.000000e+00  3.000000e+00  4.000000e+00  5.000000e+00  \n",
              "grade          7.000000e+00  7.000000e+00  8.000000e+00  1.300000e+01  \n",
              "sqft_above     1.190000e+03  1.560000e+03  2.210000e+03  9.410000e+03  \n",
              "sqft_basement  0.000000e+00  0.000000e+00  5.600000e+02  4.820000e+03  \n",
              "yr_built       1.951000e+03  1.975000e+03  1.997000e+03  2.015000e+03  \n",
              "yr_renovated   0.000000e+00  0.000000e+00  0.000000e+00  2.015000e+03  \n",
              "zipcode        9.803300e+04  9.806500e+04  9.811800e+04  9.819900e+04  \n",
              "lat            4.747100e+01  4.757180e+01  4.767800e+01  4.777760e+01  \n",
              "long          -1.223280e+02 -1.222300e+02 -1.221250e+02 -1.213150e+02  \n",
              "sqft_living15  1.490000e+03  1.840000e+03  2.360000e+03  6.210000e+03  \n",
              "sqft_lot15     5.100000e+03  7.620000e+03  1.008300e+04  8.712000e+05  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#get some information about our Data-Set\n",
        "df.info()\n",
        "df.describe().transpose()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "4b2b418e",
      "metadata": {
        "id": "4b2b418e"
      },
      "outputs": [],
      "source": [
        "# drop some unnecessary columns\n",
        "df = df.drop(['date','id','zipcode'],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "b8bc1d38",
      "metadata": {
        "id": "b8bc1d38"
      },
      "outputs": [],
      "source": [
        "X = df.drop('price',axis =1).values\n",
        "y = df['price'].values\n",
        "#splitting Train and Test\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=101)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "03518a52",
      "metadata": {
        "id": "03518a52",
        "outputId": "2fd98d1f-df60-4d4d-82fc-a30fcdcf4aac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(14480, 17)\n",
            "(14480,)\n",
            "(7133, 17)\n",
            "(7133,)\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "10e05d41",
      "metadata": {
        "id": "10e05d41",
        "outputId": "c85b9557-98e2-44e2-e3b8-9fda9e3988f7"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "module 'numpy' has no attribute 'float'.\n`np.float` was a deprecated alias for the builtin `float`. To avoid this error in existing code, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\An\\Desktop\\MachineLearning\\HousePrice\\House_Pricing_NN_Keras_core.ipynb Cell 7\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/An/Desktop/MachineLearning/HousePrice/House_Pricing_NN_Keras_core.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m \u001b[39mimport\u001b[39;00m StandardScaler\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/An/Desktop/MachineLearning/HousePrice/House_Pricing_NN_Keras_core.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m s_scaler \u001b[39m=\u001b[39m StandardScaler()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/An/Desktop/MachineLearning/HousePrice/House_Pricing_NN_Keras_core.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m X_train \u001b[39m=\u001b[39m s_scaler\u001b[39m.\u001b[39mfit_transform(X_train\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39;49mfloat))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/An/Desktop/MachineLearning/HousePrice/House_Pricing_NN_Keras_core.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m X_test \u001b[39m=\u001b[39m s_scaler\u001b[39m.\u001b[39mtransform(X_test\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mfloat))\n",
            "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\__init__.py:305\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr)\u001b[0m\n\u001b[0;32m    300\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    301\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIn the future `np.\u001b[39m\u001b[39m{\u001b[39;00mattr\u001b[39m}\u001b[39;00m\u001b[39m` will be defined as the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    302\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mcorresponding NumPy scalar.\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFutureWarning\u001b[39;00m, stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m    304\u001b[0m \u001b[39mif\u001b[39;00m attr \u001b[39min\u001b[39;00m __former_attrs__:\n\u001b[1;32m--> 305\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(__former_attrs__[attr])\n\u001b[0;32m    307\u001b[0m \u001b[39m# Importing Tester requires importing all of UnitTest which is not a\u001b[39;00m\n\u001b[0;32m    308\u001b[0m \u001b[39m# cheap import Since it is mainly used in test suits, we lazy import it\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[39m# here to save on the order of 10 ms of import time for most users\u001b[39;00m\n\u001b[0;32m    310\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[0;32m    311\u001b[0m \u001b[39m# The previous way Tester was imported also had a side effect of adding\u001b[39;00m\n\u001b[0;32m    312\u001b[0m \u001b[39m# the full `numpy.testing` namespace\u001b[39;00m\n\u001b[0;32m    313\u001b[0m \u001b[39mif\u001b[39;00m attr \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtesting\u001b[39m\u001b[39m'\u001b[39m:\n",
            "\u001b[1;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'float'.\n`np.float` was a deprecated alias for the builtin `float`. To avoid this error in existing code, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"
          ]
        }
      ],
      "source": [
        "#standardization scaler - fit&transform on train, fit only on test\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "s_scaler = StandardScaler()\n",
        "X_train = s_scaler.fit_transform(X_train.astype(np.float))\n",
        "X_test = s_scaler.transform(X_test.astype(np.float))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d2d1668",
      "metadata": {
        "id": "7d2d1668"
      },
      "outputs": [],
      "source": [
        "# Creating a Neural Network Model\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d3c36f8",
      "metadata": {
        "id": "6d3c36f8",
        "outputId": "569a1ebc-91e8-4b36-de3b-d1166f3b9195"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "102/102 [==============================] - 1s 2ms/step - loss: 429529661440.0000 - val_loss: 386740617216.0000\n",
            "Epoch 2/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 428708823040.0000 - val_loss: 384639860736.0000\n",
            "Epoch 3/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 422268796928.0000 - val_loss: 373411020800.0000\n",
            "Epoch 4/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 399729229824.0000 - val_loss: 342193766400.0000\n",
            "Epoch 5/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 349655498752.0000 - val_loss: 282749140992.0000\n",
            "Epoch 6/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 270935359488.0000 - val_loss: 205136691200.0000\n",
            "Epoch 7/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 186775470080.0000 - val_loss: 137336045568.0000\n",
            "Epoch 8/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 128713711616.0000 - val_loss: 100681695232.0000\n",
            "Epoch 9/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 101854117888.0000 - val_loss: 85251080192.0000\n",
            "Epoch 10/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 89655590912.0000 - val_loss: 76752977920.0000\n",
            "Epoch 11/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 82203443200.0000 - val_loss: 71017988096.0000\n",
            "Epoch 12/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 77039206400.0000 - val_loss: 66911756288.0000\n",
            "Epoch 13/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 73339609088.0000 - val_loss: 63909593088.0000\n",
            "Epoch 14/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 70557237248.0000 - val_loss: 61543763968.0000\n",
            "Epoch 15/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 68345798656.0000 - val_loss: 59700469760.0000\n",
            "Epoch 16/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 66475253760.0000 - val_loss: 57985552384.0000\n",
            "Epoch 17/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 64768069632.0000 - val_loss: 56384393216.0000\n",
            "Epoch 18/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 63201357824.0000 - val_loss: 54925893632.0000\n",
            "Epoch 19/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 61641031680.0000 - val_loss: 53536940032.0000\n",
            "Epoch 20/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 60176113664.0000 - val_loss: 52144091136.0000\n",
            "Epoch 21/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 58746359808.0000 - val_loss: 50839756800.0000\n",
            "Epoch 22/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 57347284992.0000 - val_loss: 49477718016.0000\n",
            "Epoch 23/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 56011898880.0000 - val_loss: 48215060480.0000\n",
            "Epoch 24/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 54665240576.0000 - val_loss: 46983053312.0000\n",
            "Epoch 25/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 53366538240.0000 - val_loss: 45776433152.0000\n",
            "Epoch 26/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 52072775680.0000 - val_loss: 44558655488.0000\n",
            "Epoch 27/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 50881835008.0000 - val_loss: 43379404800.0000\n",
            "Epoch 28/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 49636474880.0000 - val_loss: 42306383872.0000\n",
            "Epoch 29/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 48480350208.0000 - val_loss: 41189355520.0000\n",
            "Epoch 30/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 47355576320.0000 - val_loss: 40174731264.0000\n",
            "Epoch 31/300\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 46264315904.0000 - val_loss: 39128207360.0000\n",
            "Epoch 32/300\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 45243867136.0000 - val_loss: 38296592384.0000\n",
            "Epoch 33/300\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 44251541504.0000 - val_loss: 37344698368.0000\n",
            "Epoch 34/300\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 43326111744.0000 - val_loss: 36544421888.0000\n",
            "Epoch 35/300\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 42486898688.0000 - val_loss: 35705913344.0000\n",
            "Epoch 36/300\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 41692119040.0000 - val_loss: 34870599680.0000\n",
            "Epoch 37/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 40914538496.0000 - val_loss: 34307233792.0000\n",
            "Epoch 38/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 40223903744.0000 - val_loss: 33726797824.0000\n",
            "Epoch 39/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 39599771648.0000 - val_loss: 33113878528.0000\n",
            "Epoch 40/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 38992396288.0000 - val_loss: 32521949184.0000\n",
            "Epoch 41/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 38470983680.0000 - val_loss: 32091586560.0000\n",
            "Epoch 42/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 38004903936.0000 - val_loss: 31713476608.0000\n",
            "Epoch 43/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 37606002688.0000 - val_loss: 31342053376.0000\n",
            "Epoch 44/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 37240582144.0000 - val_loss: 31111536640.0000\n",
            "Epoch 45/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 36916891648.0000 - val_loss: 30912784384.0000\n",
            "Epoch 46/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 36659867648.0000 - val_loss: 30601517056.0000\n",
            "Epoch 47/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 36445040640.0000 - val_loss: 30406604800.0000\n",
            "Epoch 48/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 36210249728.0000 - val_loss: 30301079552.0000\n",
            "Epoch 49/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 36027228160.0000 - val_loss: 30070517760.0000\n",
            "Epoch 50/300\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 35889831936.0000 - val_loss: 29987672064.0000\n",
            "Epoch 51/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 35734421504.0000 - val_loss: 29926465536.0000\n",
            "Epoch 52/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 35609505792.0000 - val_loss: 29821143040.0000\n",
            "Epoch 53/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 35535679488.0000 - val_loss: 29801625600.0000\n",
            "Epoch 54/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 35377926144.0000 - val_loss: 29734625280.0000\n",
            "Epoch 55/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 35303890944.0000 - val_loss: 29843585024.0000\n",
            "Epoch 56/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 35224489984.0000 - val_loss: 29793155072.0000\n",
            "Epoch 57/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 35121233920.0000 - val_loss: 29641256960.0000\n",
            "Epoch 58/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 35014938624.0000 - val_loss: 29634156544.0000\n",
            "Epoch 59/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 34985426944.0000 - val_loss: 29527103488.0000\n",
            "Epoch 60/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 34908684288.0000 - val_loss: 29441611776.0000\n",
            "Epoch 61/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 34814214144.0000 - val_loss: 29444454400.0000\n",
            "Epoch 62/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 34745462784.0000 - val_loss: 29336549376.0000\n",
            "Epoch 63/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 34673758208.0000 - val_loss: 29443557376.0000\n",
            "Epoch 64/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 34674053120.0000 - val_loss: 29318850560.0000\n",
            "Epoch 65/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 34586615808.0000 - val_loss: 29362548736.0000\n",
            "Epoch 66/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 34515664896.0000 - val_loss: 29334528000.0000\n",
            "Epoch 67/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 34475479040.0000 - val_loss: 29245988864.0000\n",
            "Epoch 68/300\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "102/102 [==============================] - 0s 1ms/step - loss: 34410418176.0000 - val_loss: 29205874688.0000\n",
            "Epoch 69/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 34369687552.0000 - val_loss: 29237729280.0000\n",
            "Epoch 70/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 34319980544.0000 - val_loss: 29325789184.0000\n",
            "Epoch 71/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 34244530176.0000 - val_loss: 29091321856.0000\n",
            "Epoch 72/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 34244954112.0000 - val_loss: 29154885632.0000\n",
            "Epoch 73/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 34162608128.0000 - val_loss: 29105276928.0000\n",
            "Epoch 74/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 34157631488.0000 - val_loss: 29158492160.0000\n",
            "Epoch 75/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 34136166400.0000 - val_loss: 29053382656.0000\n",
            "Epoch 76/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 34044768256.0000 - val_loss: 28993636352.0000\n",
            "Epoch 77/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 34032435200.0000 - val_loss: 28985972736.0000\n",
            "Epoch 78/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 33975023616.0000 - val_loss: 28975566848.0000\n",
            "Epoch 79/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 33943302144.0000 - val_loss: 29066051584.0000\n",
            "Epoch 80/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 33868996608.0000 - val_loss: 28966162432.0000\n",
            "Epoch 81/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 33858482176.0000 - val_loss: 28945577984.0000\n",
            "Epoch 82/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 33849972736.0000 - val_loss: 28971141120.0000\n",
            "Epoch 83/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 33774245888.0000 - val_loss: 28937377792.0000\n",
            "Epoch 84/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 33731313664.0000 - val_loss: 28814960640.0000\n",
            "Epoch 85/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 33729302528.0000 - val_loss: 28759650304.0000\n",
            "Epoch 86/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 33666537472.0000 - val_loss: 28750585856.0000\n",
            "Epoch 87/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 33596344320.0000 - val_loss: 28893247488.0000\n",
            "Epoch 88/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 33611188224.0000 - val_loss: 28779055104.0000\n",
            "Epoch 89/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 33578799104.0000 - val_loss: 28795895808.0000\n",
            "Epoch 90/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 33543559168.0000 - val_loss: 28701091840.0000\n",
            "Epoch 91/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 33478191104.0000 - val_loss: 28651823104.0000\n",
            "Epoch 92/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 33471739904.0000 - val_loss: 28631156736.0000\n",
            "Epoch 93/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 33472333824.0000 - val_loss: 28806662144.0000\n",
            "Epoch 94/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 33421443072.0000 - val_loss: 28606808064.0000\n",
            "Epoch 95/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 33356990464.0000 - val_loss: 28586825728.0000\n",
            "Epoch 96/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 33367107584.0000 - val_loss: 28630167552.0000\n",
            "Epoch 97/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 33282820096.0000 - val_loss: 28601133056.0000\n",
            "Epoch 98/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 33262964736.0000 - val_loss: 28568983552.0000\n",
            "Epoch 99/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 33218056192.0000 - val_loss: 28524300288.0000\n",
            "Epoch 100/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 33220956160.0000 - val_loss: 28573659136.0000\n",
            "Epoch 101/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 33188476928.0000 - val_loss: 28473075712.0000\n",
            "Epoch 102/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 33141209088.0000 - val_loss: 28542148608.0000\n",
            "Epoch 103/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 33114288128.0000 - val_loss: 28450879488.0000\n",
            "Epoch 104/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 33095374848.0000 - val_loss: 28421150720.0000\n",
            "Epoch 105/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 33060263936.0000 - val_loss: 28398166016.0000\n",
            "Epoch 106/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 33024098304.0000 - val_loss: 28382486528.0000\n",
            "Epoch 107/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 33043025920.0000 - val_loss: 28350875648.0000\n",
            "Epoch 108/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 32969279488.0000 - val_loss: 28378116096.0000\n",
            "Epoch 109/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 32957671424.0000 - val_loss: 28319250432.0000\n",
            "Epoch 110/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 32941211648.0000 - val_loss: 28329699328.0000\n",
            "Epoch 111/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 32890707968.0000 - val_loss: 28330823680.0000\n",
            "Epoch 112/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 32876277760.0000 - val_loss: 28295102464.0000\n",
            "Epoch 113/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 32836878336.0000 - val_loss: 28281595904.0000\n",
            "Epoch 114/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 32836421632.0000 - val_loss: 28295010304.0000\n",
            "Epoch 115/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 32788332544.0000 - val_loss: 28220166144.0000\n",
            "Epoch 116/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 32773591040.0000 - val_loss: 28202268672.0000\n",
            "Epoch 117/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 32760510464.0000 - val_loss: 28124680192.0000\n",
            "Epoch 118/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 32735698944.0000 - val_loss: 28117078016.0000\n",
            "Epoch 119/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 32729188352.0000 - val_loss: 28193280000.0000\n",
            "Epoch 120/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 32712968192.0000 - val_loss: 28102787072.0000\n",
            "Epoch 121/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 32617531392.0000 - val_loss: 28095637504.0000\n",
            "Epoch 122/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 32642883584.0000 - val_loss: 28052246528.0000\n",
            "Epoch 123/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 32572100608.0000 - val_loss: 28025835520.0000\n",
            "Epoch 124/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 32579471360.0000 - val_loss: 28066263040.0000\n",
            "Epoch 125/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 32537229312.0000 - val_loss: 28129810432.0000\n",
            "Epoch 126/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 32519266304.0000 - val_loss: 28146452480.0000\n",
            "Epoch 127/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 32520749056.0000 - val_loss: 28060618752.0000\n",
            "Epoch 128/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 32448985088.0000 - val_loss: 27978747904.0000\n",
            "Epoch 129/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 32429895680.0000 - val_loss: 27989676032.0000\n",
            "Epoch 130/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 32429426688.0000 - val_loss: 28014112768.0000\n",
            "Epoch 131/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 32394872832.0000 - val_loss: 27907346432.0000\n",
            "Epoch 132/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 32396505088.0000 - val_loss: 27919546368.0000\n",
            "Epoch 133/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 32325638144.0000 - val_loss: 27921410048.0000\n",
            "Epoch 134/300\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 32347371520.0000 - val_loss: 27842840576.0000\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 135/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 32322056192.0000 - val_loss: 27944898560.0000\n",
            "Epoch 136/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 32311097344.0000 - val_loss: 27862773760.0000\n",
            "Epoch 137/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 32233746432.0000 - val_loss: 27878760448.0000\n",
            "Epoch 138/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 32258402304.0000 - val_loss: 27868596224.0000\n",
            "Epoch 139/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 32209031168.0000 - val_loss: 27813074944.0000\n",
            "Epoch 140/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 32196411392.0000 - val_loss: 27761180672.0000\n",
            "Epoch 141/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 32180318208.0000 - val_loss: 27750068224.0000\n",
            "Epoch 142/300\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 32155154432.0000 - val_loss: 27761915904.0000\n",
            "Epoch 143/300\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 32138731520.0000 - val_loss: 27691792384.0000\n",
            "Epoch 144/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 32146405376.0000 - val_loss: 27828041728.0000\n",
            "Epoch 145/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 32056793088.0000 - val_loss: 27706376192.0000\n",
            "Epoch 146/300\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 32079828992.0000 - val_loss: 27691884544.0000\n",
            "Epoch 147/300\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 32018153472.0000 - val_loss: 27643443200.0000\n",
            "Epoch 148/300\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 32025761792.0000 - val_loss: 27671447552.0000\n",
            "Epoch 149/300\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 32017473536.0000 - val_loss: 27610007552.0000\n",
            "Epoch 150/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 31960803328.0000 - val_loss: 27614306304.0000\n",
            "Epoch 151/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 31962664960.0000 - val_loss: 27687081984.0000\n",
            "Epoch 152/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 31979315200.0000 - val_loss: 27665076224.0000\n",
            "Epoch 153/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 31936491520.0000 - val_loss: 27596326912.0000\n",
            "Epoch 154/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 31883855872.0000 - val_loss: 27564939264.0000\n",
            "Epoch 155/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 31909638144.0000 - val_loss: 27561183232.0000\n",
            "Epoch 156/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 31861405696.0000 - val_loss: 27561787392.0000\n",
            "Epoch 157/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 31830980608.0000 - val_loss: 27476740096.0000\n",
            "Epoch 158/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 31832145920.0000 - val_loss: 27500904448.0000\n",
            "Epoch 159/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 31780243456.0000 - val_loss: 27460294656.0000\n",
            "Epoch 160/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 31783778304.0000 - val_loss: 27482253312.0000\n",
            "Epoch 161/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 31740874752.0000 - val_loss: 27458652160.0000\n",
            "Epoch 162/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 31751395328.0000 - val_loss: 27397953536.0000\n",
            "Epoch 163/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 31710128128.0000 - val_loss: 27465547776.0000\n",
            "Epoch 164/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 31680829440.0000 - val_loss: 27519127552.0000\n",
            "Epoch 165/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 31707729920.0000 - val_loss: 27401715712.0000\n",
            "Epoch 166/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 31646971904.0000 - val_loss: 27396098048.0000\n",
            "Epoch 167/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 31655491584.0000 - val_loss: 27351693312.0000\n",
            "Epoch 168/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 31651391488.0000 - val_loss: 27321778176.0000\n",
            "Epoch 169/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 31584143360.0000 - val_loss: 27402989568.0000\n",
            "Epoch 170/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 31595169792.0000 - val_loss: 27367213056.0000\n",
            "Epoch 171/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 31569262592.0000 - val_loss: 27377369088.0000\n",
            "Epoch 172/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 31531229184.0000 - val_loss: 27309096960.0000\n",
            "Epoch 173/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 31500695552.0000 - val_loss: 27433129984.0000\n",
            "Epoch 174/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 31520153600.0000 - val_loss: 27254523904.0000\n",
            "Epoch 175/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 31484942336.0000 - val_loss: 27265609728.0000\n",
            "Epoch 176/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 31474788352.0000 - val_loss: 27234832384.0000\n",
            "Epoch 177/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 31454394368.0000 - val_loss: 27198117888.0000\n",
            "Epoch 178/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 31410219008.0000 - val_loss: 27251132416.0000\n",
            "Epoch 179/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 31382661120.0000 - val_loss: 27156441088.0000\n",
            "Epoch 180/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 31420102656.0000 - val_loss: 27110787072.0000\n",
            "Epoch 181/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 31398950912.0000 - val_loss: 27139434496.0000\n",
            "Epoch 182/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 31363680256.0000 - val_loss: 27152846848.0000\n",
            "Epoch 183/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 31363803136.0000 - val_loss: 27150329856.0000\n",
            "Epoch 184/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 31334584320.0000 - val_loss: 27149520896.0000\n",
            "Epoch 185/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 31284965376.0000 - val_loss: 27125751808.0000\n",
            "Epoch 186/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 31302428672.0000 - val_loss: 27044513792.0000\n",
            "Epoch 187/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 31286525952.0000 - val_loss: 27042318336.0000\n",
            "Epoch 188/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 31240714240.0000 - val_loss: 27020343296.0000\n",
            "Epoch 189/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 31225839616.0000 - val_loss: 27001382912.0000\n",
            "Epoch 190/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 31234244608.0000 - val_loss: 27002912768.0000\n",
            "Epoch 191/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 31194363904.0000 - val_loss: 26992154624.0000\n",
            "Epoch 192/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 31163992064.0000 - val_loss: 26986590208.0000\n",
            "Epoch 193/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 31164538880.0000 - val_loss: 26978846720.0000\n",
            "Epoch 194/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 31137523712.0000 - val_loss: 26972157952.0000\n",
            "Epoch 195/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 31107538944.0000 - val_loss: 27032379392.0000\n",
            "Epoch 196/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 31098851328.0000 - val_loss: 26995763200.0000\n",
            "Epoch 197/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 31064543232.0000 - val_loss: 26887919616.0000\n",
            "Epoch 198/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 31065489408.0000 - val_loss: 26913001472.0000\n",
            "Epoch 199/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 31061536768.0000 - val_loss: 26906593280.0000\n",
            "Epoch 200/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 31040110592.0000 - val_loss: 26883811328.0000\n",
            "Epoch 201/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 31014578176.0000 - val_loss: 26864461824.0000\n",
            "Epoch 202/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 31002779648.0000 - val_loss: 26838806528.0000\n",
            "Epoch 203/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 31003994112.0000 - val_loss: 26840754176.0000\n",
            "Epoch 204/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 30946877440.0000 - val_loss: 26805729280.0000\n",
            "Epoch 205/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 30940416000.0000 - val_loss: 26787375104.0000\n",
            "Epoch 206/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 30925514752.0000 - val_loss: 26869348352.0000\n",
            "Epoch 207/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 30915885056.0000 - val_loss: 26808328192.0000\n",
            "Epoch 208/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 30885836800.0000 - val_loss: 26780540928.0000\n",
            "Epoch 209/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 30885009408.0000 - val_loss: 26746580992.0000\n",
            "Epoch 210/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 30885586944.0000 - val_loss: 26739955712.0000\n",
            "Epoch 211/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 30836226048.0000 - val_loss: 26743973888.0000\n",
            "Epoch 212/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 30868058112.0000 - val_loss: 26709749760.0000\n",
            "Epoch 213/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 30811774976.0000 - val_loss: 26687295488.0000\n",
            "Epoch 214/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 30810527744.0000 - val_loss: 26703894528.0000\n",
            "Epoch 215/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 30761885696.0000 - val_loss: 26782478336.0000\n",
            "Epoch 216/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 30782365696.0000 - val_loss: 26661650432.0000\n",
            "Epoch 217/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 30764328960.0000 - val_loss: 26709295104.0000\n",
            "Epoch 218/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 30730700800.0000 - val_loss: 26627461120.0000\n",
            "Epoch 219/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 30703667200.0000 - val_loss: 26664894464.0000\n",
            "Epoch 220/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 30705887232.0000 - val_loss: 26588784640.0000\n",
            "Epoch 221/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 30690369536.0000 - val_loss: 26624274432.0000\n",
            "Epoch 222/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 30653286400.0000 - val_loss: 26588368896.0000\n",
            "Epoch 223/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 30664638464.0000 - val_loss: 26573201408.0000\n",
            "Epoch 224/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 30630762496.0000 - val_loss: 26539323392.0000\n",
            "Epoch 225/300\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 30633084928.0000 - val_loss: 26518984704.0000\n",
            "Epoch 226/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 30702755840.0000 - val_loss: 26556272640.0000\n",
            "Epoch 227/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 30571091968.0000 - val_loss: 26515628032.0000\n",
            "Epoch 228/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 30554744832.0000 - val_loss: 26497646592.0000\n",
            "Epoch 229/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 30591488000.0000 - val_loss: 26497611776.0000\n",
            "Epoch 230/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 30551007232.0000 - val_loss: 26494418944.0000\n",
            "Epoch 231/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 30514219008.0000 - val_loss: 26509156352.0000\n",
            "Epoch 232/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 30517084160.0000 - val_loss: 26490134528.0000\n",
            "Epoch 233/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 30529114112.0000 - val_loss: 26553784320.0000\n",
            "Epoch 234/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 30494031872.0000 - val_loss: 26520715264.0000\n",
            "Epoch 235/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 30463047680.0000 - val_loss: 26418014208.0000\n",
            "Epoch 236/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 30466942976.0000 - val_loss: 26443739136.0000\n",
            "Epoch 237/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 30551103488.0000 - val_loss: 26658707456.0000\n",
            "Epoch 238/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 30450597888.0000 - val_loss: 26407170048.0000\n",
            "Epoch 239/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 30381406208.0000 - val_loss: 26369898496.0000\n",
            "Epoch 240/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 30376527872.0000 - val_loss: 26356400128.0000\n",
            "Epoch 241/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 30357463040.0000 - val_loss: 26332127232.0000\n",
            "Epoch 242/300\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 30370033664.0000 - val_loss: 26302873600.0000\n",
            "Epoch 243/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 30366189568.0000 - val_loss: 26349139968.0000\n",
            "Epoch 244/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 30319163392.0000 - val_loss: 26309249024.0000\n",
            "Epoch 245/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 30314901504.0000 - val_loss: 26369492992.0000\n",
            "Epoch 246/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 30319579136.0000 - val_loss: 26278864896.0000\n",
            "Epoch 247/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 30287046656.0000 - val_loss: 26265501696.0000\n",
            "Epoch 248/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 30272286720.0000 - val_loss: 26246082560.0000\n",
            "Epoch 249/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 30243725312.0000 - val_loss: 26243219456.0000\n",
            "Epoch 250/300\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 30266728448.0000 - val_loss: 26211344384.0000\n",
            "Epoch 251/300\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 30209290240.0000 - val_loss: 26211840000.0000\n",
            "Epoch 252/300\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 30200897536.0000 - val_loss: 26181181440.0000\n",
            "Epoch 253/300\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 30217721856.0000 - val_loss: 26151245824.0000\n",
            "Epoch 254/300\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 30173663232.0000 - val_loss: 26162329600.0000\n",
            "Epoch 255/300\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 30180986880.0000 - val_loss: 26178181120.0000\n",
            "Epoch 256/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 30178701312.0000 - val_loss: 26136793088.0000\n",
            "Epoch 257/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 30136965120.0000 - val_loss: 26134671360.0000\n",
            "Epoch 258/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 30110246912.0000 - val_loss: 26122043392.0000\n",
            "Epoch 259/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 30153621504.0000 - val_loss: 26118547456.0000\n",
            "Epoch 260/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 30124533760.0000 - val_loss: 26155071488.0000\n",
            "Epoch 261/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 30076696576.0000 - val_loss: 26070956032.0000\n",
            "Epoch 262/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 30076264448.0000 - val_loss: 26059608064.0000\n",
            "Epoch 263/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 30050154496.0000 - val_loss: 26051184640.0000\n",
            "Epoch 264/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 30039080960.0000 - val_loss: 26054498304.0000\n",
            "Epoch 265/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 30050846720.0000 - val_loss: 26101768192.0000\n",
            "Epoch 266/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 30043152384.0000 - val_loss: 25992407040.0000\n",
            "Epoch 267/300\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "102/102 [==============================] - 0s 1ms/step - loss: 29999597568.0000 - val_loss: 26036045824.0000\n",
            "Epoch 268/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 29993965568.0000 - val_loss: 26046111744.0000\n",
            "Epoch 269/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 29974587392.0000 - val_loss: 26028521472.0000\n",
            "Epoch 270/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 29978451968.0000 - val_loss: 25970982912.0000\n",
            "Epoch 271/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 29916051456.0000 - val_loss: 26010200064.0000\n",
            "Epoch 272/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 29926299648.0000 - val_loss: 25994743808.0000\n",
            "Epoch 273/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 29905526784.0000 - val_loss: 25943613440.0000\n",
            "Epoch 274/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 29894017024.0000 - val_loss: 25963935744.0000\n",
            "Epoch 275/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 29891420160.0000 - val_loss: 25919477760.0000\n",
            "Epoch 276/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 29889392640.0000 - val_loss: 25893300224.0000\n",
            "Epoch 277/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 29837666304.0000 - val_loss: 25963630592.0000\n",
            "Epoch 278/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 29859487744.0000 - val_loss: 25964351488.0000\n",
            "Epoch 279/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 29839802368.0000 - val_loss: 25908131840.0000\n",
            "Epoch 280/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 29820497920.0000 - val_loss: 25909207040.0000\n",
            "Epoch 281/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 29810388992.0000 - val_loss: 25868955648.0000\n",
            "Epoch 282/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 29811564544.0000 - val_loss: 25843392512.0000\n",
            "Epoch 283/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 29808357376.0000 - val_loss: 25810769920.0000\n",
            "Epoch 284/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 29758730240.0000 - val_loss: 25866706944.0000\n",
            "Epoch 285/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 29770952704.0000 - val_loss: 25849174016.0000\n",
            "Epoch 286/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 29755996160.0000 - val_loss: 25806462976.0000\n",
            "Epoch 287/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 29744228352.0000 - val_loss: 25767649280.0000\n",
            "Epoch 288/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 29719848960.0000 - val_loss: 25757374464.0000\n",
            "Epoch 289/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 29750130688.0000 - val_loss: 25756555264.0000\n",
            "Epoch 290/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 29711599616.0000 - val_loss: 25750628352.0000\n",
            "Epoch 291/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 29689292800.0000 - val_loss: 25738541056.0000\n",
            "Epoch 292/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 29674260480.0000 - val_loss: 25719877632.0000\n",
            "Epoch 293/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 29655402496.0000 - val_loss: 25725560832.0000\n",
            "Epoch 294/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 29628946432.0000 - val_loss: 25721870336.0000\n",
            "Epoch 295/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 29619730432.0000 - val_loss: 25694427136.0000\n",
            "Epoch 296/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 29629913088.0000 - val_loss: 25726048256.0000\n",
            "Epoch 297/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 29625806848.0000 - val_loss: 25704658944.0000\n",
            "Epoch 298/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 29587521536.0000 - val_loss: 25681434624.0000\n",
            "Epoch 299/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 29568055296.0000 - val_loss: 25673711616.0000\n",
            "Epoch 300/300\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 29558343680.0000 - val_loss: 25619271680.0000\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(64,activation='relu'))\n",
        "model.add(Dense(32,activation='relu'))\n",
        "model.add(Dense(16,activation='relu'))\n",
        "model.add(Dense(1)) #If you don't specify anything, no activation is applied (ie. \"linear\" activation: a(x) = x).\n",
        "#model.compile(optimizer='Adam',loss=tf.keras.losses.MeanAbsoluteError())\n",
        "model.compile(optimizer='Adam',loss=tf.keras.losses.MeanSquaredError())\n",
        "\n",
        "history = model.fit(x=X_train,y=y_train, validation_split=0.1,\n",
        "          batch_size=128,epochs=300)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b0b91cd",
      "metadata": {
        "id": "4b0b91cd",
        "outputId": "c85553f4-6b53-44f6-96d2-391dff5632ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_18 (Dense)            (None, 64)                1152      \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 16)                1040      \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,209\n",
            "Trainable params: 2,209\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "803359f8",
      "metadata": {
        "id": "803359f8",
        "outputId": "c771215e-45f7-48bb-88de-5f04f6c4954a"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#loss_df = pd.DataFrame(model.history.history)\n",
        "#loss_df.plot(figsize=(12,8))\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26bc0a6c",
      "metadata": {
        "id": "26bc0a6c",
        "outputId": "81166947-d059-49df-e519-aae82d6b4dd1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "223/223 [==============================] - 0s 738us/step\n",
            "MAE: 111719.89244313403\n"
          ]
        }
      ],
      "source": [
        "#compare actual output values with predicted values\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# evaluate the performance of the algorithm (MAE - MSE - RMSE)\n",
        "from sklearn import metrics\n",
        "print('MAE:', metrics.mean_absolute_error(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b62ad627",
      "metadata": {
        "id": "b62ad627"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "613f6b49",
      "metadata": {
        "id": "613f6b49"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
